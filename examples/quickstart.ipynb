{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixtcha Quickstart Guide\n",
    "\n",
    "## Step 0: Sign Up and get an API Key at https://mixtcha.com. \n",
    "\n",
    "Then, save that key in a .env file, in the same subfolder as this notebook \n",
    "\n",
    "`MIXTCHA_API_KEY = sk-mix-1234`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make sure your API key is saved in .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv() #you should have already written .env in Step 0\n",
    "\n",
    "# alternatively - paste your Mixtcha.com API key\n",
    "#MIXTCHA_API_KEY=\"sk-1234\"\n",
    "\n",
    "# Assert that MIXTCHA_API_KEY is present in the environment\n",
    "assert 'MIXTCHA_API_KEY' in os.environ, \"MIXTCHA_API_KEY is not set in the environment. Please make sure it's in your .env file.\"\n",
    "\n",
    "# if you really aren't sure, print it out\n",
    "#print(os.getenv(\"MIXTCHA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Directly setting a mixtcha configuration\n",
    "\n",
    "We need to set our `base_url=\"https://api.mixtcha.com/\"` to talk to the mixtcha server and use the `MIXTCHA_API_KEY`.\n",
    "\n",
    "The mixtcha server uses the `model` variable to configure the mixtcha. It can accept YAML, JSON, URLs and single LLM model names. To start, let's show how to directly set a mixtcha configuration. \n",
    "\n",
    "This configuration is going to call both `gpt-4o` and `claude-3.5-sonnet` in parallel, and then have `claude-3.5-sonnet` synthesize a single final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's my synthesized, critically evaluated explanation of what a mixture of agents means:\n",
      "\n",
      "A mixture of agents refers to a collaborative AI system where multiple specialized AI models or \"agents\" work together to solve complex tasks more effectively than any single agent could alone. Think of it like a skilled professional team where each member has distinct expertise and responsibilities.\n",
      "\n",
      "Key aspects of agent mixtures:\n",
      "\n",
      "1. Specialized Capabilities\n",
      "- Each agent is designed or trained for specific types of tasks\n",
      "- Agents complement each other's strengths and compensate for weaknesses\n",
      "- Example: One agent might excel at language processing while another at image recognition\n",
      "\n",
      "2. Coordinated Collaboration\n",
      "- A management system or \"meta-controller\" orchestrates the agents\n",
      "- It determines which agent(s) should handle specific aspects of a task\n",
      "- Ensures efficient task distribution based on agent capabilities\n",
      "\n",
      "3. Adaptive Performance\n",
      "- The system can learn which combinations of agents work best for different scenarios\n",
      "- Improves over time through experience and feedback\n",
      "- Provides greater flexibility in handling diverse challenges\n",
      "\n",
      "A practical example would be a customer service system where:\n",
      "- One agent handles initial customer classification\n",
      "- Another specializes in technical troubleshooting\n",
      "- A third manages billing queries\n",
      "- A coordinator directs customers to the appropriate specialist\n",
      "\n",
      "This approach offers greater versatility and reliability than single-agent systems, as it combines specialized expertise while maintaining coordinated operation.\n"
     ]
    }
   ],
   "source": [
    "#set up the client\n",
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"MIXTCHA_API_KEY\"),\n",
    "    base_url=\"https://api.mixtcha.com\"\n",
    ")\n",
    "\n",
    "#define the mixtcha configuration\n",
    "config = {\n",
    "        \"layers\": [\n",
    "            {\n",
    "                \"type\": \"parallel\",\n",
    "                \"models\": [\"openai/gpt-4o\", \"anthropic/claude-3.5-sonnet\"]\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"aggregator\",\n",
    "                \"model\": \"anthropic/claude-3.5-sonnet\",\n",
    "                \"prompt\": \"Multiple answers were provided between <option> tags, but don't assume that I've seen them. Please synthesize them into a single, high-quality response. It is crucial to critically evaluate the information provided in these responses, recognizing that some of it may be incorrect. Think step-by-step before providing your final answer.\"\n",
    "            }\n",
    "        ],\n",
    "        \"messageMode\": \"inline\",\n",
    "        \"delimiter\": [\"<option>\", \"</option>\"]\n",
    "    }\n",
    "\n",
    "# Convert config to YAML string\n",
    "import yaml\n",
    "config_yaml = yaml.dump(config, default_flow_style=True)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=config_yaml,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What do you know about creating a 'mixture of agents'? Explain it in a way that is easy to understand.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: What's going on under the hood?\n",
    "\n",
    "The main benefit of mixtcha is to make it easy to leverage many LLMs while still having the client work as a single query and a single response. However, we can inspect the intermediate responses to see what is going on under the hood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer 1 (parallel) - Raw responses from each model:\n",
      "\n",
      "openai/gpt-4o:\n",
      "Creating a \"mixture of agents\" refers to combining different AI models or systems, known as \"agents,\" to solve complex tasks more effectively than any single agent could manage on its own. Think of it like assembling a team where each member brings a unique skill set to the table, allowing the team to tackle a wider variety of problems and adapt to different situations. \n",
      "\n",
      "Here’s a simple breakdown:\n",
      "\n",
      "1. **Diversity of Skills**: Each agent in the mixture might specialize in different areas. For example, one agent could be great at recognizing images, while another might excel at processing language.\n",
      "\n",
      "2. **Collaboration**: These agents work together, sharing information and dividing tasks based on their strengths. Just like a soccer team has different players for different roles (goalkeeper, defender, striker), a mixture of agents allows for specialized roles.\n",
      "\n",
      "3. **Decision Making**: Typically, there is a system that manages or coordinates these agents, deciding which agent or combination of agents should handle each part of the task. This is often done using a \"meta-controller\" or some sort of decision algorithm.\n",
      "\n",
      "4. **Learning and Adaptation**: Over time, the mixture can learn which combinations of agents work best for different types of problems. This can be achieved through training and feedback, much like a sports team improves its strategies through practice and after analyzing past games.\n",
      "\n",
      "5. **Flexibility and Robustness**: By using multiple agents, the system can become more flexible and robust. If one agent struggles with a particular problem, another agent might be able to handle it, reducing the risk of failure.\n",
      "\n",
      "Overall, the mixture of agents approach leverages the strengths of various AI models to create a more capable and versatile system. It allows for a form of collaborative problem-solving that mimics how humans or teams might divide and conquer tasks based on individual strengths.\n",
      "\n",
      "anthropic/claude-3.5-sonnet:\n",
      "A mixture of agents is like having different AI specialists working together as a team, each with their own expertise. Let me explain it with a simple analogy:\n",
      "\n",
      "Imagine a restaurant kitchen:\n",
      "- One chef specializes in appetizers\n",
      "- Another in main courses\n",
      "- A third in desserts\n",
      "- And a manager coordinates their work\n",
      "\n",
      "In AI terms, a mixture of agents works similarly:\n",
      "1. Different agents handle specific tasks they're best at\n",
      "2. They can work together to solve complex problems\n",
      "3. Often there's a coordinator agent that manages the others\n",
      "4. Each agent can have different capabilities or \"personalities\"\n",
      "\n",
      "Real-world example:\n",
      "A customer service system might use:\n",
      "- One agent for initial greeting and basic questions\n",
      "- Another for technical support\n",
      "- A third for billing inquiries\n",
      "- A coordinator to direct customers to the right specialist\n",
      "\n",
      "The key benefit is that specialized agents can perform better at their specific tasks than a single \"jack of all trades\" agent.\n",
      "\n",
      "Layer 2 (aggregator) - Final synthesized response:\n",
      "Here's my synthesized, critically evaluated explanation of what a mixture of agents means:\n",
      "\n",
      "A mixture of agents refers to a collaborative AI system where multiple specialized AI models or \"agents\" work together to solve complex tasks more effectively than any single agent could alone. Think of it like a skilled professional team where each member has distinct expertise and responsibilities.\n",
      "\n",
      "Key aspects of agent mixtures:\n",
      "\n",
      "1. Specialized Capabilities\n",
      "- Each agent is designed or trained for specific types of tasks\n",
      "- Agents complement each other's strengths and compensate for weaknesses\n",
      "- Example: One agent might excel at language processing while another at image recognition\n",
      "\n",
      "2. Coordinated Collaboration\n",
      "- A management system or \"meta-controller\" orchestrates the agents\n",
      "- It determines which agent(s) should handle specific aspects of a task\n",
      "- Ensures efficient task distribution based on agent capabilities\n",
      "\n",
      "3. Adaptive Performance\n",
      "- The system can learn which combinations of agents work best for different scenarios\n",
      "- Improves over time through experience and feedback\n",
      "- Provides greater flexibility in handling diverse challenges\n",
      "\n",
      "A practical example would be a customer service system where:\n",
      "- One agent handles initial customer classification\n",
      "- Another specializes in technical troubleshooting\n",
      "- A third manages billing queries\n",
      "- A coordinator directs customers to the appropriate specialist\n",
      "\n",
      "This approach offers greater versatility and reliability than single-agent systems, as it combines specialized expertise while maintaining coordinated operation.\n"
     ]
    }
   ],
   "source": [
    "# The intermediate_responses field contains the raw responses from each layer\n",
    "print(\"\\nLayer 1 (parallel) - Raw responses from each model:\")\n",
    "for completion in response.intermediate_responses['layers'][0]['completions']:\n",
    "    print(f\"\\n{completion['model']}:\")\n",
    "    print(completion['choices'][0]['message']['content'])\n",
    "\n",
    "print(\"\\nLayer 2 (aggregator) - Final synthesized response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: How much does Mixtcha cost?\n",
    "\n",
    "The list of all available models and their prices is available at [https://mixtcha.com/models_list.yaml](https://mixtcha.com/models_list.yaml). Charges are rounded to the nearest penny and the minimum charge for a mixtcha completion is $0.01. We can inspect our last call to see the pricing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Costs by layer:\n",
      "\n",
      "Layer 1 (parallel):\n",
      "  openai/gpt-4o:\n",
      "  Cost: $0.005711\n",
      "  anthropic/claude-3.5-sonnet:\n",
      "  Cost: $0.004829\n",
      "\n",
      "Layer 2 (aggregator):\n",
      "  anthropic/claude-3.5-sonnet:\n",
      "  Cost: $0.009806\n",
      "\n",
      "Sum of raw costs: $0.020345\n",
      "Final rounded cost: $0.02\n"
     ]
    }
   ],
   "source": [
    "# Print costs from all layers\n",
    "print(\"\\nCosts by layer:\")\n",
    "total_raw_cost = 0\n",
    "\n",
    "for layer_idx, layer in enumerate(response.intermediate_responses['layers']):\n",
    "    print(f\"\\nLayer {layer_idx + 1} ({layer['layer_type']}):\")\n",
    "    for completion in layer['completions']:\n",
    "        print(f\"  {completion['model']}:\")\n",
    "        if 'usage' in completion:\n",
    "            cost = completion['usage'].get('cost', 0)\n",
    "            total_raw_cost += cost\n",
    "            print(f\"  Cost: ${cost:.6f}\")\n",
    "\n",
    "print(f\"\\nSum of raw costs: ${total_raw_cost:.6f}\")\n",
    "print(f\"Final rounded cost: ${response.usage.cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create your own mixtchas and share them!\n",
    "\n",
    "You can make your own mixtchas as YAML or JSON files and share them online. See the [type definitions](https://github.com/mixtcha/mixtcha/blob/main/reference/types.ts) for help making your own mixtchas. You can share them as a GitHub Gist, raw GitHub file, or any other method you have to host a publicly-available file on the internet.\n",
    "\n",
    "In the example below, we load this same configuration from the url to the file on GitHub.\n",
    "\n",
    "**Warning: Always inspect the configuration file before running a mixture from URL! Mixtcha configurations can potentially contain harmful content or prompt injection attacks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a \"neural network of LLMs\" (large language models) is a conceptual idea that envisions linking multiple LLMs to function together in a structured system, similar to how neurons are interconnected in traditional neural networks. Here’s a synthesized explanation of how such a system might work, potential challenges, and benefits:\n",
      "\n",
      "### Architecture and Design\n",
      "1. **Hierarchical Structure:**\n",
      "   - The system could have a hierarchical design where LLMs operate at various abstraction levels, with lower-level LLMs handling specific tasks and higher-level LLMs coordinating the output.\n",
      "   - This mirrors how specialized regions in the human brain process information before integrating it into a coherent response.\n",
      "\n",
      "2. **Parallel and Specialized Processing:**\n",
      "   - Multiple LLMs could process different aspects of a task simultaneously, each specializing in distinct types of reasoning or domains.\n",
      "   - Such specialization could optimize efficiency, as individual models can be tailored to excel in particular areas, enhancing the overall processing capability.\n",
      "\n",
      "3. **Inter-node Communication:**\n",
      "   - Effective communication protocols would be essential for passing information between LLMs, which could involve standardized embeddings or token exchanges.\n",
      "   - Methods for integrating responses from various LLMs into a single coherent output are crucial.\n",
      "\n",
      "### Training and Learning\n",
      "1. **Integrated Training Strategy:**\n",
      "   - A novel training strategy might be necessary to train the entire network as a cohesive unit, potentially using advanced techniques in gradient passing or reinforcement learning.\n",
      "   - Feedback mechanisms, analogous to backpropagation, could help fine-tune both individual LLMs and the system collectively based on output quality.\n",
      "\n",
      "2. **Transfer Learning:**\n",
      "   - Leveraging pre-trained LLMs for fine-tuning within the system could improve training efficiency and adaptability.\n",
      "\n",
      "### Scalability and Efficiency\n",
      "1. **Resource Management:**\n",
      "   - Given the resource-intensive nature of LLMs, efficient computational resource management would be vital. Techniques like model pruning or distillation might be employed to reduce resource consumption.\n",
      "\n",
      "2. **Parallelization and Latency:**\n",
      "   - Implementing parallel processing strategies could enhance operational efficiency and reduce response times. Addressing communication and processing delays is crucial for maintaining performance.\n",
      "\n",
      "### Applications and Use Cases\n",
      "- Such a network could handle complex, multi-faceted tasks, with potential deployments in advanced AI systems for decision-making, virtual assistants, or multi-modal systems.\n",
      "- It might be particularly effective in scenarios demanding a broad spectrum of expertise or tasks requiring complex reasoning.\n",
      "\n",
      "### Challenges\n",
      "1. **Complexity and Coordination:**\n",
      "   - Managing the complexity of coordinating multiple LLMs, ensuring consistency, and resolving conflicting outputs.\n",
      "   - Developing sophisticated integration mechanisms to ensure coherent final outputs.\n",
      "\n",
      "2. **Bias and Safety:**\n",
      "   - Similar to individual models, a combined network could amplify biases or errors, necessitating robust mitigation strategies.\n",
      "\n",
      "### Benefits\n",
      "- Enhanced reasoning capabilities and reliability due to specialization and redundancy.\n",
      "- Ability to handle complex, nuanced tasks more effectively compared to a single LLM.\n",
      "\n",
      "This concept remains largely theoretical and would require significant advancements in AI architecture, data handling, and computational capabilities to realize fully. However, the potential for harnessing the strengths and specializations of multiple LLMs could lead to powerful and advanced AI systems.\n"
     ]
    }
   ],
   "source": [
    "# The URL to the 4oSo mixtcha configuration\n",
    "model_url = \"https://github.com/mixtcha/mixtcha/raw/refs/heads/main/official-mixtchas/4oSo.yaml\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_url,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What would it be like to make a 'neural network of LLMs'?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
